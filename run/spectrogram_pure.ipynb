{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf8f8234-81a7-463a-83bf-9419e56ba929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import src.custom_transforms as CT\n",
    "from scipy import signal\n",
    "from scipy.signal import ShortTimeFFT\n",
    "from scipy.signal.windows import gaussian\n",
    "from scipy.signal import stft, istft\n",
    "from src.Dataset import AudioMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9933bf9-292c-4d08-9ae8-dc5ad271ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate=22050\n",
    "n_fft=512\n",
    "root = '../Data'\n",
    "\n",
    "transforms = [\n",
    "    CT.TrimSilence(5),\n",
    "    CT.TimeStretchFixLength(sample_rate)\n",
    "]\n",
    "\n",
    "dataset = AudioMNIST(root, target_sample_rate=sample_rate/2, transform=T.Compose(transforms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "745c1745",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m Audio(data\u001b[38;5;241m=\u001b[39mx, rate\u001b[38;5;241m=\u001b[39msample_rate)\n",
      "File \u001b[1;32md:\\Users\\kaasa\\Documents\\DriveBackup\\GitHub\\Audio-MNIST-Generation\\run\\src\\Dataset.py:57\u001b[0m, in \u001b[0;36mAudioMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     Zxx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(waveform)\n\u001b[1;32m---> 57\u001b[0m Zxx \u001b[38;5;241m=\u001b[39m \u001b[43mZxx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     58\u001b[0m Zxx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomplex_to_2d(Zxx\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(Zxx\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "x, _ = dataset[11]\n",
    "Audio(data=x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403a939-8cad-4e92-8eaa-c4045a94cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26f1f23-4b25-4610-ae6a-f9dcee00b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "(3584 - 256)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "133065f3-2d6e-4f41-917f-76fa95698892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "#(x.shape- nperseg) % (nperseg-noverlap) == 0)\n",
    "\n",
    "f, t, Zxx = scipy.signal.stft(x, sample_rate/2, nperseg = n_fft/2, noverlap = n_fft/4, window='hann')\n",
    "        # get amplitude\n",
    "Zxx = Zxx[0:128, :-1]\n",
    "#Zxx = np.abs(Zxx[0:128, :-1])\n",
    "#Zxx = np.atleast_3d(Zxx).transpose(2,0,1)\n",
    "        # convert to decibel\n",
    "#Zxx = librosa.amplitude_to_db(Zxx, ref = np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a42543-6c46-4ffa-8a6b-b97836f43852",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d4d97b5-e7b5-4df8-8b97-7c47980777e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_to_2d(tensor: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Converts complex IQ to two channels representing real and imaginary\n",
    "\n",
    "    Args:\n",
    "        tensor (:class:`numpy.ndarray`):\n",
    "            (batch_size, vector_length, ...)-sized tensor.\n",
    "\n",
    "    Returns:\n",
    "        transformed (:class:`numpy.ndarray`):\n",
    "            Expanded vectors\n",
    "    \"\"\"\n",
    "\n",
    "    new_tensor = np.zeros((2, tensor.shape[0]), dtype=np.float64)\n",
    "    new_tensor[0] = np.real(tensor).astype(np.float64)\n",
    "    new_tensor[1] = np.imag(tensor).astype(np.float64)\n",
    "    return new_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4794e30d-5508-4995-98c5-2899ee0b9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = complex_to_2d(Zxx.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26d7791d-777d-47d1-8519-b3e5a5cc10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint=datapoint.reshape(2,128,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe20444-531d-427c-b763-382a84137d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ea466-5159-4620-bc3d-f36818ea328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxxx = np.abs(Zxx)\n",
    "Zxxx = np.atleast_3d(Zxxx).transpose(2,0,1)\n",
    "        # convert to decibel\n",
    "Zxxx = librosa.amplitude_to_db(Zxxx, ref = np.max)\n",
    "import matplotlib.pyplot as plt\n",
    "librosa.display.specshow(Zxxx[0])\n",
    "plt.title(\"Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa8cc79c-d23a-4151-a73a-19023671f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twod_to_complex(tensor: np.ndarray):\n",
    "    \"\"\"Converts complex IQ to two channels representing real and imaginary\n",
    "\n",
    "    Args:\n",
    "        tensor (:class:`numpy.ndarray`):\n",
    "            (batch_size, vector_length, ...)-sized tensor.\n",
    "\n",
    "    Returns:\n",
    "        transformed (:class:`numpy.ndarray`):\n",
    "            Expanded vectors\n",
    "    \"\"\"\n",
    "    tmp_tensor = tensor.reshape(2, tensor.shape[1]*tensor.shape[2])\n",
    "    new_tensor = np.zeros((1, tmp_tensor.shape[1]), dtype=np.complex64)\n",
    "    new_tensor[0] = tmp_tensor[0,:]+ 1j * tmp_tensor[1,:]\n",
    "    new_tensor=new_tensor.reshape(1, tensor.shape[1],tensor.shape[2])\n",
    "    return new_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb5250-d3c8-4a54-82b3-e19d3c0bf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx_rec=twod_to_complex(datapoint)\n",
    "Zxx_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd3b77-6bd3-42d9-970b-e0976e7b3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_,x = scipy.signal.istft(Zxx_rec, sample_rate/2)\n",
    "        # get amplitude\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad279fc-26bf-403d-af09-dede926a65e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=x, rate=sample_rate/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f246fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
